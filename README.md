## Education

MBA | Western Governors University (Starting June 2025)<br>
B.S., Business Analytics | Bellevue University (Starting June 2025)<br>
B.S., Mathematics | Bellevue University (Starting June 2025)<br>
M.S., Data Science | Bellevue University (Aug 2023 - Mar 2025)<br>
Certificate of Training in Database Querying with SQL | OpenClassrooms (Apr 2023)<br>
B.S., Computer Science w/ minor in Mathematics | California State University of Northridge (Aug 2020 - May 2022)<br>

## Work Experience

### Target Corporation | Jun 2018 - Present
*General Merchandise/Fulfillment Expert*
- Efficiently fulfill digital guest orders by selecting, preparing, packing, and sorting items for order pickup, drive-up, and shipping to home.
- Ensure accuracy in order processing and timely delivery to meet guest demand and productivity metrics.
- Expertly manage select store areas to maintain a well-zoned, stocked, and signed sales floor, ensuring guest satisfaction and optimal sales performance.
- Acknowledge guests while efficiently completing workload, prioritize tasks based on sales trends, execute promotions, planograms, and price changes, and maintain inventory accuracy through backroom organization and inbound delivery processing.

### Gamestar+ | Dec 2021
*QA Contract Engineer*
- QA Alpha builds for user focus testing on workflow and continuity.
- Documented blocker bugs and raised priority for fixes to developers.

## Projects

### [Tumor Cell Nuclei Analysis](https://github.com/Oc18a/Nathanael-Ochoa-Project-Portfolio/tree/main/Tumor%20Cell%20Nuclei%20Analysis)
- This project analyzes tumor cell nuclei characteristics in breast cancer to distinguish between benign and malignant tumors. Inspired by personal experiences with breast cancer, the dataset used comes from a 1992 study that aimed to diagnose breast tumors using fine needle aspirations (FNAs) and image processing. The study analyzed tumor cell features to predict malignancy without a full biopsy. The project explores the impact of size, shape, and texture of tumor cell nuclei on classification. After applying machine learning models, including Logistic Regression, Random Forest, and Support Vector Machine (SVM), Logistic Regression achieved the highest accuracy of 97.74% with 5-fold cross-validation. Key features like radius, area, and concave points were most influential in predicting tumor malignancy.

### [Correlations Between Blood Pressure, Cholesterol, and Cardiovascular Disease](https://github.com/Oc18a/Nathanael-Ochoa-Project-Portfolio/tree/main/Correlations%20Between%20Blood%20Pressure%2C%20Cholesterol%2C%20and%20Cardiovascular%20Disease)
- This project analyzes the correlations between blood pressure, cholesterol levels, and the risk of cardiovascular disease (CVD). Using a dataset of 70,000 patient records, the goal is to explore how factors like age, blood pressure, cholesterol, weight, smoking, physical activity, and alcohol consumption contribute to the likelihood of cardiovascular disease. Various methods such as Exploratory Data Analysis (EDA), Pearson correlation, Chi-Square tests, and logistic regression models were used to identify significant predictors. The Random Forest classifier was also employed to enhance prediction accuracy. The findings suggest that age, cholesterol, and systolic blood pressure are the strongest predictors of CVD, while lifestyle factors like smoking and physical activity show weaker but still significant correlations. The project includes an analysis paper, code implementation, and a slideshow summarizing key insights.

### [AI-Powered Employee Break and Lunch Scheduling](https://github.com/Oc18a/Nathanael-Ochoa-Project-Portfolio/tree/main/AI-Powered%20Employee%20Break%20and%20Lunch%20Scheduling)
- This project is an AI-driven solution designed to automate the process of creating break and lunch schedules for retail employees. The system leverages OpenAI's GPT-4 model, fine-tuned on historical scheduling data, to generate optimized schedules based on various constraints, such as shift lengths, break timings, and minimizing overlap between team member breaks. The project uses a combination of Jupyter Notebook for model training, Python for data processing, and Streamlit for creating an intuitive user interface. The Streamlit app allows team leaders to input employee shift details and automatically generate a break/lunch schedule, streamlining the scheduling process and saving valuable time. The app can be run and stopped directly from the Jupyter Notebook, making the entire process seamless and efficient.

### [Childcare Company Market Expansion Analysis](https://github.com/Oc18a/Nathanael-Ochoa-Project-Portfolio/tree/main/Childcare%20Company%20Market%20Expansion%20Analysis)
- This project aimed to provide actionable insights into weekly median child care prices across U.S. counties and cities to support DV Child Care's potential market expansion. The analysis, based on a decade of data (2008-2018), identified a clear trend of rising prices over time, reflecting broader economic shifts. I focused on presenting findings through an interactive dashboard, a summary brief, and a slideshow tailored for stakeholders, enabling informed decision-making. Assumptions about data accuracy were made for simplicity, with some variables excluded for clarity. Although demographic correlations with pricing weren't fully explored, the analysis provides a strong foundation for understanding market trends and informing expansion strategies.

### [Optimizing E-Commerce Store Profits](https://github.com/Oc18a/Nathanael-Ochoa-Project-Portfolio/tree/main/Optimizing%20E-Commerce%20Store%20Profits)
- This project aimed to enhance the profitability of an e-commerce jewelry store, "630 Jewelers," by developing a product recommender system and an inventory management model. Using data from customer purchase history, the recommender was built using content-based filtering and cosine similarity to suggest products based on item features. For inventory management, an Exponential Smoothing model, specifically the Holt-Winters method, was applied to forecast demand for a high-frequency product, achieving a Mean Absolute Error (MAE) of 2.85, indicating satisfactory forecasting accuracy. The project’s recommendations include integrating the recommender at checkout and in email marketing, prioritizing slow-selling inventory, and using the inventory model to adjust stock orders. These improvements aim to increase sales and optimize inventory management for the business.

### [Manga to Anime - Predicting Adaptation Potential](https://github.com/Oc18a/Nathanael-Ochoa-Project-Portfolio/tree/main/Manga%20to%20Anime%20-%20Predicting%20Adaptation%20Potential)
- This project aimed to develop a predictive model for determining which manga series are worth adapting into anime, using data from MyAnimeList. By analyzing manga ratings and comparing them to anime adaptation ratings, the goal was to create a model that could assist executives in making informed decisions about resource allocation for new anime projects. After cleaning and preparing the data, the analysis compared several machine learning models, ultimately selecting the Random Forest Classifier for its highest accuracy of 93.5%. Despite challenges such as missing data and the need to average anime scores, the model showed promise, and further refinements could enhance its predictive power. The project highlighted the potential for data analytics in the anime industry to minimize financial risks and maximize opportunities.

### [Correlation Between House Features and Pricing](https://github.com/Oc18a/Nathanael-Ochoa-Project-Portfolio/tree/main/Correlation%20Between%20House%20Features%20and%20Pricing)
- This project explores the correlation between house features and pricing using the USA Real Estate Dataset from Kaggle, focusing on data from Delaware. Key variables analyzed include the number of bedrooms, bathrooms, house size, and location. Data cleaning involved removing rows with missing values or incorrect statuses, and the analysis was limited to Delaware due to visualization challenges posed by the dataset's large size and numerous outliers. The goal was to determine if these house features have a significant correlation with pricing. While factors like house condition and additional features (e.g., garage, neighborhood safety) were not available in the dataset, they were noted as potential improvements for future analyses. The project provides insights into the relationship between house features and pricing but acknowledges the limitations due to the dataset's structure and the absence of certain key variables.

### [Analyzing Previous Olympic Games Data](https://github.com/Oc18a/Nathanael-Ochoa-Portfolio.github.io/tree/main/Analyzing%20Previous%20Olympic%20Games%20Data)
- This project analyzed past Summer Olympic Games data to predict the outcomes of the Paris 2024 Olympics. Using datasets on Olympic sports, athlete events, and medals from 1896-2020, I focused on the top countries with the most medals—USA, Australia, and China—due to Russia's absence in recent Games. By comparing medal trends and performance, I estimated which country might outperform the others in 2024. The data counted medals awarded to athletes or teams, which may have caused slight discrepancies compared to typical medal counts.

### [City Weather with API](https://github.com/Oc18a/Nathanael-Ochoa-Project-Portfolio/tree/main/City%20Weather%20with%20API)
- This program interacts with a web service to retrieve weather data for a user-specified location within the U.S. Users can search by city name and state code or ZIP/postal code and specify their preferred units of measurement (e.g., Celsius or Fahrenheit). The program allows for multiple consecutive searches, with input validation checks in place to ensure only valid data is entered. It is designed to provide accurate and accessible weather information with a simple and user-friendly interface.

### [Data Analysis with SQL](https://github.com/Oc18a/Nathanael-Ochoa-Project-Portfolio/tree/main/Data%20Analysis%20with%20SQL)
- In OpenClassrooms' mock project, I was hired as a freelance Data Analyst by Datazine, a French online magazine. Over a 3-month contract, my tasks included identifying key user indicators, determining the optimal times for content posting, and assessing the potential profit of launching an English version of the magazine in the U.S. I created a database in MySQL Workbench, using SQL create statements to establish six tables and then uploaded six provided CSV files. I followed a PowerPoint guide that included prompts with questions, SQL query spaces, and answer sections to complete the project.
